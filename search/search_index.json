{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome About How to read Author","title":"Welcome"},{"location":"#welcome","text":"","title":"Welcome"},{"location":"#about","text":"","title":"About"},{"location":"#how-to-read","text":"","title":"How to read"},{"location":"#author","text":"","title":"Author"},{"location":"failure/failure/","text":"Failure Recovery Electrical Router Driver Worker Hard-drive MIND Spark Hadoop Delta","title":"Failure Recovery"},{"location":"failure/failure/#failure-recovery","text":"","title":"Failure Recovery"},{"location":"failure/failure/#electrical","text":"","title":"Electrical"},{"location":"failure/failure/#router","text":"","title":"Router"},{"location":"failure/failure/#driver","text":"","title":"Driver"},{"location":"failure/failure/#worker","text":"","title":"Worker"},{"location":"failure/failure/#hard-drive","text":"","title":"Hard-drive"},{"location":"failure/failure/#mind","text":"","title":"MIND"},{"location":"failure/failure/#spark","text":"","title":"Spark"},{"location":"failure/failure/#hadoop","text":"","title":"Hadoop"},{"location":"failure/failure/#delta","text":"","title":"Delta"},{"location":"services/ansible/","text":"Ansible Overview The Setup Role","title":"Ansible"},{"location":"services/ansible/#ansible","text":"","title":"Ansible"},{"location":"services/ansible/#overview","text":"","title":"Overview"},{"location":"services/ansible/#the-setup-role","text":"","title":"The Setup Role"},{"location":"services/hadoop/","text":"Hadoop Overview Web APIs CLI Examples","title":"Hadoop"},{"location":"services/hadoop/#hadoop","text":"","title":"Hadoop"},{"location":"services/hadoop/#overview","text":"","title":"Overview"},{"location":"services/hadoop/#web-apis","text":"","title":"Web APIs"},{"location":"services/hadoop/#cli","text":"","title":"CLI"},{"location":"services/hadoop/#examples","text":"","title":"Examples"},{"location":"services/hardware/","text":"3 Infrastructure A functioning computer cluster is a complicated collection of services and pro- grams that needs to be properly setup and configured. Clouds are common today where the user rarely have not need to care about the specifics off hard- ware or networking, so called managed services. This cluster is on-premise, meaning that we are responsible for everything ourselves. How can we roughly divide the different parts of the cluster? 3.1 Hardware Maybe just say desktop computers instead of HP EliteDesk? 10 HP EliteDesk 800 G3 TWR desktop computers with 32GiB ram, Intel Core i7-7700 CPU @ 3.60GHz. Quad core. The processor was released in 2017 and is part of Intel\u2019s 7th generation of Core processors. Each have roughly 8TB of internal disk memory with some variations due to hardware availability. The Ubuntu Server (22.04.02)? operating system is in- stalled on a 500GiB SSD. All in all the system has roughly 70TB+ of usable disk space. Complementing the setup are two Intel NUC8i5BEK mini PCs with 32Gib ram, Intel Core i5-8258U CPU @ 2.30GHz quadcore, with a 500GiB SSD disk. Re- leased in 2018. 3.2 Provisioning: Ansible Ansible is an open-source automation tool used for managing and configuring systems. Our use case lies in provisioning and configuration management. By distributing the correct networking information and credentials, mounting cifs shares, installing software: java, spark, hadoop, while sending out configuration files to each node and allocating available disk space to the distributed file system. This is done by writing an Ansible playbook which contains a series of tasks you wish for the nodes to complete. 3.3 Compute: Spark (with YARN) Apache Spark is an open-source distributed computing engine for processing large distributed datasets. It support multiple high-level APIs for languages such as Scala, Python, Java, and R. It also works with regular SQL queries. Configuration. 3.4 Store: hdfs (with delta) Hadoop Distributed File System works by dividing data into blocks that are replicated across a cluster, ensuring high-availability and fault tolerance 3 Mobile network data https://en.wikipedia.org/wiki/Mobility management https://en.wikipedia.org/wiki/Location area identity 3rd Generation Partnership Project; Technical Specification Group Core Net- work and Terminals; Numbering, addressing and identification (Release 9) The data consist of mobile network data where each entry represents a con- nection between a cellular device and some kind of an antenna. The schema is pretty complicated but to highlight the columns of interest: Timestamp: The time when the data was collected. The discretization is down to a couple of minutes. IMSI: International Mobile Subscriber Identity, a unique identifier for the cel- lular device stored on the SIM card. In practice this number is transmitted as rarely as possible and instead a random temporary number is assigned. (source?) MCC: Mobile country code. A three digit code which shows from which country the operator of the subscriber is based. Hence if you are subscribed to an Italian mobile operator your MCC is 222 and will be logged as such even if you travel abroads. (source?) LAC: 3.1 What: example, how much 3.2 Schema: IMSI, LAC, SAC, TAC, E-NODE, SECTOR 3.3 Some stats: counts, log-times, proportions","title":"Hardware"},{"location":"services/spark/","text":"Spark Overview Web APIs Examples","title":"Spark"},{"location":"services/spark/#spark","text":"","title":"Spark"},{"location":"services/spark/#overview","text":"","title":"Overview"},{"location":"services/spark/#web-apis","text":"","title":"Web APIs"},{"location":"services/spark/#examples","text":"","title":"Examples"},{"location":"usage/1_start_up/","text":"Starting the cluster Router and VPN PCs Network and mounts Spark Hadoop Delta","title":"Starting the cluster"},{"location":"usage/1_start_up/#starting-the-cluster","text":"","title":"Starting the cluster"},{"location":"usage/1_start_up/#router-and-vpn","text":"","title":"Router and VPN"},{"location":"usage/1_start_up/#pcs","text":"","title":"PCs"},{"location":"usage/1_start_up/#network-and-mounts","text":"","title":"Network and mounts"},{"location":"usage/1_start_up/#spark","text":"","title":"Spark"},{"location":"usage/1_start_up/#hadoop","text":"","title":"Hadoop"},{"location":"usage/1_start_up/#delta","text":"","title":"Delta"},{"location":"usage/2_dev_env/","text":"Connecting your dev-env","title":"Connecting your dev-env"},{"location":"usage/2_dev_env/#connecting-your-dev-env","text":"","title":"Connecting your dev-env"},{"location":"usage/3_mind_interface/","text":"Interfacing with MIND Overview Filtered Ingestion and Large Job Batches Transformations further filters llong/llat geographic trajectories movement and data usage profiles Saving to Delta","title":"Interfacing with MIND"},{"location":"usage/3_mind_interface/#interfacing-with-mind","text":"","title":"Interfacing with MIND"},{"location":"usage/3_mind_interface/#overview","text":"","title":"Overview"},{"location":"usage/3_mind_interface/#filtered-ingestion-and-large-job-batches","text":"","title":"Filtered Ingestion and Large Job Batches"},{"location":"usage/3_mind_interface/#transformations","text":"","title":"Transformations"},{"location":"usage/3_mind_interface/#further-filters","text":"","title":"further filters"},{"location":"usage/3_mind_interface/#llongllat","text":"","title":"llong/llat"},{"location":"usage/3_mind_interface/#geographic","text":"","title":"geographic"},{"location":"usage/3_mind_interface/#trajectories","text":"","title":"trajectories"},{"location":"usage/3_mind_interface/#movement-and-data-usage-profiles","text":"","title":"movement and data usage profiles"},{"location":"usage/3_mind_interface/#saving-to-delta","text":"","title":"Saving to Delta"}]}